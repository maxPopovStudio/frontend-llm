# frontend-llm

## Опис

Frontend застосунок для візуалізації даних з вільного мінімально структурованого тексту. Система автоматично аналізує текст за допомогою локальної LLM моделі та обирає найкращий тип діаграми для візуалізації на основі структури даних.

**Технологічний стек:**

- React + MobX для управління станом
- transformers.js для роботи з LLM моделями
- ECharts для візуалізації діаграм
- Whisper Web для голосового вводу

## Основні можливості

### Функціональність

1. **Вибір LLM моделі** - Користувач може обрати через яку LLM буде аналізуватись текст
   - На старті підтримується GPT-2
   - Архітектура дозволяє легко додати нові моделі (через transformers.js)
   - Нові розробники можуть швидко підключити нову модель, перезібрати застосунок і запустити

2. **Відображення кроків аналізу** - Користувач бачить всі кроки обробки:
   - Промпт, який використовується на кожному кроці
   - Результат виконання промпту
   - Покрокова візуалізація процесу структурування тексту та вибору діаграми

3. **Голосовий ввід** - Можливість ввести текст через голосовий ввід:
   - Використовується бібліотека Whisper Web
   - Відображення процесу обробки аудіо
   - При успішному результаті текст автоматично вставляється в поле для аналізу

## Архітектура

### Структура проекту

- Чітке розділення на компоненти, stores, services, utils, types
- Single-page application (без роутингу)

### Управління станом (MobX)

Використовуються спеціалізовані stores для різних частин системи:

- TextAnalysisStore - управління процесом аналізу тексту
- ChartStore - управління діаграмами та їх конфігурацією
- LLMStore - управління LLM моделями та їх завантаженням
- VoiceInputStore - управління голосовим вводом

### Компонентна архітектура

Основні React компоненти:

- TextInput - поле вводу тексту
- ChartVisualization - відображення діаграми ECharts
- AnalysisSteps - відображення кроків аналізу з промптами та результатами
- LLMSelector - вибір LLM моделі
- VoiceInput - компонент для голосового вводу

## Процес аналізу тексту

### Пайплайн обробки

Система використовує покроковий аналіз через LLM промпти, що особливо важливо для моделей з невеликим контекстним вікном (наприклад, GPT-2):

1. **Промпти зберігаються в окремому JSON файлі** - для легкого редагування та розширення
2. **Покрокова обробка** - текст аналізується поетапно, кожен крок має свій промпт
3. **Витягування структурованих даних** - тільки через LLM промпти (без regex або NER)
4. **Валідація даних** - валідація також виконується через LLM промпти
5. **Вибір типу діаграми** - на основі:
   - LLM промптів
   - Опису діаграм з файлу `echarts-chart-types.json`
   - Алгоритм обходить типи діаграм в циклі, оцінюючи вірогідність для кожного типу
   - Обирається тип з найвищою вірогідністю

### Обмеження

- **Максимальна довжина тексту**: 1024 символи
- Система відображає кількість введених символів
- При перевищенні ліміту користувач отримує попередження

### Обробка помилок

- При помилках парсингу - відображення помилки на відповідному кроці обробки
- При недостатніх даних - інформативне повідомлення користувачу
- При помилках завантаження/виконання моделей - відображення помилки з кнопкою "Повторити спробу"

## Візуалізація (ECharts)

### Конфігурація діаграм

- Конфігурація генерується на основі опису діаграм з файлу `echarts-chart-types.json`
- Теми та кольорові схеми налаштовуються через LLM промпти
- Діаграми адаптивні для різних розмірів екрану
- Підтримуються інтерактивні можливості ECharts (tooltip, zoom, brush)

### Підтримувані типи діаграм

Система підтримує наступні типи діаграм (описані в `echarts-chart-types.json`):

- Лінійна діаграма
- Стовпчаста діаграма
- Згрупована стовпчаста діаграма
- Кругова діаграма
- Діаграма розсіювання
- Діаграма з областями
- Радіальна діаграма
- Воронкоподібна діаграма
- Діаграма-спідометр
- Теплова карта

## Продуктивність та оптимізація

### Web Workers

- Обробка LLM виконується в Web Workers для неблокуючої роботи UI
- UI залишається відзивчивим під час обробки

### Кешування

- **Моделі**: Локальне кешування в браузері (IndexedDB/Cache API)
- Моделі завантажуються тільки один раз, потім використовуються з кешу
- **CDN**: Моделі завантажуються з CDN для швидшого доступу

### Lazy Loading

- Моделі та компоненти завантажуються за потреби
- Оптимізація bundle size для швидшого старту застосунку

## Деплой та запуск

### Статичний хостинг

- Застосунок може бути задеплоєний як статичний сайт (GitHub Pages, Netlify, Vercel)
- Можливий локальний запуск
- Підтримка Docker для контейнеризації

### Build процес

- Використовується сучасний build tool (Vite/Webpack) для оптимальної збірки
- Моделі не входять в bundle, завантажуються окремо з CDN

### Environment Variables

- Environment variables не обов'язкові для базової конфігурації
- Можуть використовуватись для кастомізації CDN URL або інших налаштувань

## Сумісність

### Підтримка браузерів

- **Браузери**: Тільки браузери з підтримкою GPU (для transformers.js та WebAssembly)
- **Мобільні пристрої**: Підтримується
- **Offline mode**: Обов'язково підтримується після завантаження моделей

### Мультимовність

- Підтримка аналізу тексту різними мовами
- Залежить від можливостей обраної LLM моделі

## Розробка

### Додавання нових LLM моделей

1. Модель повинна бути сумісна з transformers.js
2. Додати конфігурацію моделі в відповідний store
3. Перезібрати застосунок
4. Запустити локально або задеплоїти

### Редагування промптів

Промпти для аналізу зберігаються в окремому JSON файлі, що дозволяє:

- Легко редагувати промпти без зміни коду
- Додавати нові кроки аналізу
- Налаштовувати поведінку системи

## Особливості реалізації

- **Немає редагування проміжних результатів** - користувач бачить тільки фінальний результат
- **Немає історії аналізів** - кожен аналіз виконується незалежно
- **Один тип діаграми** - система обирає один найкращий тип, не пропонує множинний вибір
- **Fallback стратегія** - якщо структура даних не відповідає жодному типу діаграми, користувач отримує повідомлення на відповідному кроці обробки
